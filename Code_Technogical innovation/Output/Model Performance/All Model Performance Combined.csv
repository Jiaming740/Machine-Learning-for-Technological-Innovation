,Unnamed: 0,Name,Type,Share,True-Positives,False-Negatives,False-Positives,True-Negatives,Accuracy,AUC,Precision,Recall,F1
0,2,XLNet (Chinese),Transformer,0.423,0.927,0.936,0.073,0.064,0.932,0.93,0.927,0.915,0.921
1,5,BERT-wwm (Chinese),Transformer,0.438,0.909,0.944,0.091,0.056,0.928,0.928,0.909,0.926,0.917
2,3,ELECTRA (Chinese),Transformer,0.432,0.911,0.938,0.089,0.062,0.927,0.926,0.911,0.918,0.915
3,0,BERT (Chinese),Transformer,0.441,0.904,0.945,0.096,0.055,0.927,0.927,0.904,0.928,0.916
0,7,Multi Layer Perceptron,Embedding Vectors,0.436,0.898,0.935,0.102,0.065,0.919,0.918,0.898,0.914,0.906
4,4,MacBERT (Chinese),Transformer,0.445,0.891,0.941,0.109,0.059,0.919,0.92,0.891,0.924,0.908
1,1,Support Vector Classifier (RBF),Embedding Vectors,0.45,0.879,0.94,0.121,0.06,0.913,0.914,0.879,0.923,0.901
0,5,Random Forest,Bag of Words,0.444,0.882,0.932,0.118,0.068,0.91,0.91,0.882,0.912,0.897
1,1,Support Vector Classifier (RBF),Bag of Words,0.425,0.898,0.918,0.102,0.082,0.909,0.907,0.898,0.89,0.894
2,3,Logistic Regression,Bag of Words,0.438,0.88,0.922,0.12,0.078,0.904,0.903,0.88,0.898,0.889
0,3,Power data Word2Vec,CNN,0.46,0.861,0.94,0.139,0.06,0.904,0.906,0.861,0.925,0.892
2,4,Random Forest,Embedding Vectors,0.423,0.891,0.91,0.109,0.09,0.902,0.899,0.891,0.878,0.885
3,8,Gradient Boosting Classifier,Embedding Vectors,0.442,0.873,0.923,0.127,0.077,0.901,0.901,0.873,0.9,0.887
4,2,Logistic Regression,Embedding Vectors,0.445,0.87,0.924,0.13,0.076,0.9,0.9,0.87,0.902,0.886
3,10,LASSO,Bag of Words,0.431,0.879,0.912,0.121,0.088,0.898,0.896,0.879,0.884,0.882
5,3,Ridge Regression,Embedding Vectors,0.458,0.854,0.93,0.146,0.07,0.895,0.897,0.854,0.911,0.881
6,9,LASSO,Embedding Vectors,0.46,0.852,0.931,0.148,0.069,0.895,0.897,0.852,0.914,0.882
4,4,Ridge Regression,Bag of Words,0.437,0.871,0.914,0.129,0.086,0.895,0.894,0.871,0.887,0.879
7,10,Linear Regression,Embedding Vectors,0.458,0.852,0.929,0.148,0.071,0.894,0.896,0.852,0.91,0.88
1,1,Chinese Word2Vec,CNN,0.435,0.871,0.911,0.129,0.089,0.894,0.892,0.871,0.883,0.877
2,2,FastText,CNN,0.418,0.886,0.899,0.114,0.101,0.894,0.89,0.886,0.864,0.875
5,1,RoBERTa (Chinese),Transformer,0.401,0.9,0.886,0.1,0.114,0.892,0.885,0.9,0.841,0.869
5,9,Gradient Boosting Classifier,Bag of Words,0.418,0.88,0.895,0.12,0.105,0.889,0.885,0.88,0.857,0.869
8,11,Robust Regression,Embedding Vectors,0.476,0.831,0.937,0.169,0.063,0.886,0.891,0.831,0.923,0.875
6,8,Multi Layer Perceptron,Bag of Words,0.433,0.858,0.899,0.142,0.101,0.881,0.879,0.858,0.866,0.862
7,7,Decision Tree with Bagging,Bag of Words,0.412,0.875,0.883,0.125,0.117,0.88,0.875,0.875,0.84,0.857
9,5,Decision Tree with Boosting,Embedding Vectors,0.451,0.841,0.91,0.159,0.09,0.879,0.879,0.841,0.884,0.862
10,0,Nearest Neighbors,Embedding Vectors,0.498,0.807,0.946,0.193,0.054,0.877,0.884,0.807,0.936,0.867
11,6,Decision Tree with Bagging,Embedding Vectors,0.404,0.878,0.876,0.122,0.124,0.877,0.871,0.878,0.827,0.852
8,6,Decision Tree with Boosting,Bag of Words,0.433,0.85,0.892,0.15,0.108,0.874,0.872,0.85,0.857,0.854
9,12,Robust Regression,Bag of Words,0.44,0.844,0.896,0.156,0.104,0.873,0.872,0.844,0.865,0.854
10,2,Naive Bayes,Bag of Words,0.5,0.792,0.933,0.208,0.067,0.863,0.87,0.792,0.922,0.852
11,11,Linear Regression,Bag of Words,0.445,0.812,0.878,0.188,0.122,0.849,0.848,0.812,0.843,0.827
3,0,No Embeddings,CNN,0.482,0.788,0.905,0.212,0.095,0.849,0.854,0.788,0.886,0.834
12,0,Nearest Neighbors,Bag of Words,0.344,0.877,0.806,0.123,0.194,0.83,0.814,0.877,0.703,0.78
